{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:29:58.209459Z",
          "start_time": "2020-10-30T01:29:56.398724Z"
        },
        "id": "nGzagluypwiD",
        "outputId": "7c938185-fa07-4477-bf49-c444bc7ef27c"
      },
      "source": [
        "#importing Useful DataStructures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#importing Misc Libraries\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "\n",
        "#for 100% jupyter notebook cell width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "\n",
        "#sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:29:58.281245Z",
          "start_time": "2020-10-30T01:29:58.211405Z"
        },
        "id": "sXFAp8umpwiI"
      },
      "source": [
        "class final_pipeline:\n",
        "    '''\n",
        "    Final Pipeline for Prediction of Test Datapoints\n",
        "    \n",
        "    Contains 5 member Functions:\n",
        "        1. init method\n",
        "        2. load_required_files method\n",
        "        3. preprocessing method\n",
        "        4. final_function_1 method\n",
        "        5. final_function_2 method\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, file_directory = ''):\n",
        "        '''\n",
        "        This function is used to initialize the Class members. It also loads up the required files for pre-processing and predictions\n",
        "        once instantiated.\n",
        "        \n",
        "        Inputs:\n",
        "            self\n",
        "            file_directory: str, default = ''\n",
        "                Path of the directory where the file is stored\n",
        "        \n",
        "        Returns:\n",
        "            None\n",
        "        '''\n",
        "        \n",
        "        self.file_directory = file_directory\n",
        "        self.load_required_files()\n",
        "        \n",
        "    def load_required_files(self):\n",
        "        '''\n",
        "        Function to load all the required files for Pre-processing and prediction. Gets called when the \n",
        "        class gets initialized\n",
        "        \n",
        "        Inputs:\n",
        "            self\n",
        "            \n",
        "        Returns:\n",
        "            Pre-processed DataFrame\n",
        "        '''\n",
        "        \n",
        "        #loading important files\n",
        "        with open(self.file_directory + 'relational_table.pkl', 'rb') as f:\n",
        "            self.relational_table = pickle.load(f)\n",
        "        #loading final columns list\n",
        "        with open(self.file_directory + 'Final_XGBOOST_Selected_features.pkl', 'rb') as f:\n",
        "            self.final_cols = pickle.load(f)\n",
        "        #loading te columns for modelling for ext_sources\n",
        "        with open(self.file_directory + 'columns_for_ext_values_predictor.pkl', 'rb') as f:\n",
        "            self.columns_for_modelling = pickle.load(f)\n",
        "        #loading XGBRegressor models for predicting missing EXT_SOURCE fields\n",
        "        with open(self.file_directory + 'Nan EXT source predictors/nan_EXT_SOURCE_1_xgbr_model.pkl', 'rb') as f:\n",
        "            self.xgbr_ext_1 = pickle.load(f)\n",
        "        with open(self.file_directory + 'Nan EXT source predictors/nan_EXT_SOURCE_2_xgbr_model.pkl', 'rb') as f:\n",
        "            self.xgbr_ext_2 = pickle.load(f)\n",
        "        with open(self.file_directory + 'Nan EXT source predictors/nan_EXT_SOURCE_3_xgbr_model.pkl', 'rb') as f:\n",
        "            self.xgbr_ext_3 = pickle.load(f)\n",
        "        #loading LGBMRegressor model for predicting Count Payments for data\n",
        "        with open(self.file_directory + 'cnt_payment_predictor_lgbmr.pkl', 'rb') as f:\n",
        "            self.cnt_payment_lgbmr = pickle.load(f)\n",
        "        #loading the training target values\n",
        "        with open(self.file_directory + 'Train_TARGET.pkl', 'rb') as f:\n",
        "            self.TARGET = pickle.load(f)\n",
        "        #loading KNN model for TARGET_500_neighbors feature\n",
        "        with open(self.file_directory + 'KNN_model_TARGET_500_neighbors.pkl', 'rb') as f:\n",
        "            self.knn_target_500_neighbors = pickle.load(f)\n",
        "        #loading grouped interactions for several groupings\n",
        "        file_names = ['Application_train_grouped_interactions_NAME_CONTRACT_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE.pkl',\n",
        "                      'Application_train_grouped_interactions_CODE_GENDER_NAME_FAMILY_STATUS_NAME_INCOME_TYPE.pkl',\n",
        "                      'Application_train_grouped_interactions_FLAG_OWN_CAR_FLAG_OWN_REALTY_NAME_INCOME_TYPE.pkl',\n",
        "                      'Application_train_grouped_interactions_NAME_EDUCATION_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE.pkl',\n",
        "                      'Application_train_grouped_interactions_OCCUPATION_TYPE_ORGANIZATION_TYPE.pkl',\n",
        "                      'Application_train_grouped_interactions_CODE_GENDER_FLAG_OWN_CAR_FLAG_OWN_REALTY.pkl']\n",
        "        self.group_interactions_tables = []\n",
        "        for group_interactions_file_name in file_names:\n",
        "            with open(self.file_directory + 'Grouped Interactions/' + group_interactions_file_name, 'rb') as f:\n",
        "                self.group_interactions_tables.append(pickle.load(f))\n",
        "        \n",
        "        #loading final model for prediction\n",
        "        with open(self.file_directory + 'Final Prediction XGB/' + 'clf_xgboost_fold_1_model_600feats.pkl', 'rb') as f:\n",
        "            self.final_xgb_1 = pickle.load(f)\n",
        "        with open(self.file_directory + 'Final Prediction XGB/' + 'clf_xgboost_fold_2_model_600feats.pkl', 'rb') as f:\n",
        "            self.final_xgb_2 = pickle.load(f)\n",
        "        with open(self.file_directory + 'Final Prediction XGB/' + 'clf_xgboost_fold_3_model_600feats.pkl', 'rb') as f:\n",
        "            self.final_xgb_3 = pickle.load(f)\n",
        "        #threshold for class label\n",
        "        self.threshold = 0.04579606279730797\n",
        "    \n",
        "    def preprocessing(self, data):\n",
        "        '''\n",
        "        Function to preprocess the data into required format for predictions\n",
        "        \n",
        "        Inputs:\n",
        "            self\n",
        "            data: DataFrame\n",
        "                The Test DataFrame\n",
        "            \n",
        "        Returns:\n",
        "            None        \n",
        "        '''\n",
        "        \n",
        "        #dropping flag columns\n",
        "        flag_cols_to_drop = ['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12',\n",
        "                    'FLAG_DOCUMENT_20']\n",
        "        data = data.drop(flag_cols_to_drop, axis = 1)\n",
        "        #converting age to years\n",
        "        data['DAYS_BIRTH'] = data['DAYS_BIRTH'] * -1 / 365\n",
        "        #removing erroneous points\n",
        "        data['DAYS_EMPLOYED'][data['DAYS_EMPLOYED'] == 365243] = np.nan\n",
        "        data['OBS_30_CNT_SOCIAL_CIRCLE'][data['OBS_30_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
        "        data['OBS_60_CNT_SOCIAL_CIRCLE'][data['OBS_60_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
        "        #filling NaN values for categorical columns with 'XNA'\n",
        "        categorical_columns = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
        "        data[categorical_columns] = data[categorical_columns].fillna('XNA')\n",
        "        #converting columns of REGION_RATING_CLIENT to object type\n",
        "        data['REGION_RATING_CLIENT'] = data['REGION_RATING_CLIENT'].astype('object')\n",
        "        data['REGION_RATING_CLIENT_W_CITY'] = data['REGION_RATING_CLIENT_W_CITY'].astype('object')\n",
        "        #counting the total NaN values for each application\n",
        "        data['MISSING_VALS_TOTAL_APP'] = data.isna().sum(axis = 1)\n",
        "        \n",
        "        #we need to predict missing EXT_SOURCE Values if any\n",
        "        columns_for_modelling = self.columns_for_modelling\n",
        "        #defining the list of models\n",
        "        xgbr_ext_models = [self.xgbr_ext_2, self.xgbr_ext_3, self.xgbr_ext_1]\n",
        "        for index, ext_col in enumerate(['EXT_SOURCE_2','EXT_SOURCE_3','EXT_SOURCE_1']):\n",
        "            #checking if the value is missing or not\n",
        "            if data[ext_col].isna().sum() > 0:\n",
        "                X_test_missing = data[data[ext_col].isna()][columns_for_modelling]\n",
        "                data[ext_col][data[ext_col].isna()] = xgbr_ext_models[index].predict(X_test_missing)\n",
        "                \n",
        "            #adding the predicted column to columns for modelling for next column's prediction\n",
        "            columns_for_modelling = columns_for_modelling + [ext_col]\n",
        "        \n",
        "        #creating numeric features\n",
        "        #income and credit features\n",
        "        data['CREDIT_INCOME_RATIO'] = data['AMT_CREDIT'] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        data['CREDIT_ANNUITY_RATIO'] = data['AMT_CREDIT'] / (data['AMT_ANNUITY'] + 0.00001)\n",
        "        data['ANNUITY_INCOME_RATIO'] = data['AMT_ANNUITY'] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        data['INCOME_ANNUITY_DIFF'] = data['AMT_INCOME_TOTAL'] - data['AMT_ANNUITY']\n",
        "        data['CREDIT_GOODS_RATIO'] = data['AMT_CREDIT'] / (data['AMT_GOODS_PRICE'] + 0.00001)\n",
        "        data['CREDIT_GOODS_DIFF'] = data['AMT_CREDIT'] - data['AMT_GOODS_PRICE'] + 0.00001\n",
        "        data['GOODS_INCOME_RATIO'] = data['AMT_GOODS_PRICE'] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        data['INCOME_EXT_RATIO'] = data['AMT_INCOME_TOTAL'] / (data['EXT_SOURCE_3'] + 0.00001)\n",
        "        data['CREDIT_EXT_RATIO'] = data['AMT_CREDIT'] / (data['EXT_SOURCE_3'] + 0.00001)\n",
        "        #age ratios and diffs\n",
        "        data['AGE_EMPLOYED_DIFF'] = data['DAYS_BIRTH'] - data['DAYS_EMPLOYED']\n",
        "        data['EMPLOYED_TO_AGE_RATIO'] = data['DAYS_EMPLOYED'] / (data['DAYS_BIRTH'] + 0.00001)\n",
        "        #car ratios\n",
        "        data['CAR_EMPLOYED_DIFF'] = data['OWN_CAR_AGE'] - data['DAYS_EMPLOYED']\n",
        "        data['CAR_EMPLOYED_RATIO'] = data['OWN_CAR_AGE'] / (data['DAYS_EMPLOYED']+0.00001)\n",
        "        data['CAR_AGE_DIFF'] = data['DAYS_BIRTH'] - data['OWN_CAR_AGE']\n",
        "        data['CAR_AGE_RATIO'] = data['OWN_CAR_AGE'] / (data['DAYS_BIRTH'] + 0.00001)\n",
        "        #flag contacts sum\n",
        "        data['FLAG_CONTACTS_SUM'] = data['FLAG_MOBIL'] + data['FLAG_EMP_PHONE'] + data['FLAG_WORK_PHONE'] + data[\n",
        "                                    'FLAG_CONT_MOBILE'] + data['FLAG_PHONE'] + data['FLAG_EMAIL']\n",
        "        \n",
        "        data['HOUR_PROCESS_CREDIT_MUL'] = data['AMT_CREDIT'] * data['HOUR_APPR_PROCESS_START']\n",
        "        #family members\n",
        "        data['CNT_NON_CHILDREN'] = data['CNT_FAM_MEMBERS'] - data['CNT_CHILDREN']\n",
        "        data['CHILDREN_INCOME_RATIO'] = data['CNT_CHILDREN'] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        data['PER_CAPITA_INCOME'] = data['AMT_INCOME_TOTAL'] / (data['CNT_FAM_MEMBERS'] + 1)\n",
        "        #region ratings\n",
        "        data['REGIONS_RATING_INCOME_MUL'] = (data['REGION_RATING_CLIENT'] + data['REGION_RATING_CLIENT_W_CITY']) * data['AMT_INCOME_TOTAL'] / 2\n",
        "        data['REGION_RATING_MAX'] = [max(ele1, ele2) for ele1, ele2 in zip(data['REGION_RATING_CLIENT'], data['REGION_RATING_CLIENT_W_CITY'])]\n",
        "        data['REGION_RATING_MAX'] = [min(ele1, ele2) for ele1, ele2 in zip(data['REGION_RATING_CLIENT'], data['REGION_RATING_CLIENT_W_CITY'])]\n",
        "        data['REGION_RATING_MEAN'] = (data['REGION_RATING_CLIENT'] + data['REGION_RATING_CLIENT_W_CITY']) / 2\n",
        "        data['REGION_RATING_MUL'] = data['REGION_RATING_CLIENT'] * data['REGION_RATING_CLIENT_W_CITY']\n",
        "        #flag regions\n",
        "        data['FLAG_REGIONS'] = data['REG_REGION_NOT_LIVE_REGION'] + data['REG_REGION_NOT_WORK_REGION'] + data['LIVE_REGION_NOT_WORK_REGION']+data[\n",
        "                                'REG_CITY_NOT_LIVE_CITY'] + data['REG_CITY_NOT_WORK_CITY'] + data['LIVE_CITY_NOT_WORK_CITY']   \n",
        "        #ext_sources\n",
        "        data['EXT_SOURCE_MEAN'] = (data['EXT_SOURCE_1'] + data['EXT_SOURCE_2'] + data['EXT_SOURCE_3'] ) / 3\n",
        "        data['EXT_SOURCE_MUL'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3'] \n",
        "        data['EXT_SOURCE_MAX'] = [max(ele1,ele2,ele3) for ele1, ele2, ele3 in zip(data['EXT_SOURCE_1'], data['EXT_SOURCE_2'], data['EXT_SOURCE_3'])]\n",
        "        data['EXT_SOURCE_MIN'] = [min(ele1,ele2,ele3) for ele1, ele2, ele3 in zip(data['EXT_SOURCE_1'], data['EXT_SOURCE_2'], data['EXT_SOURCE_3'])]\n",
        "        data['EXT_SOURCE_VAR'] = [np.var([ele1,ele2,ele3]) for ele1, ele2, ele3 in zip(data['EXT_SOURCE_1'], data['EXT_SOURCE_2'], data['EXT_SOURCE_3'])]\n",
        "        data['WEIGHTED_EXT_SOURCE'] =  data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
        "        #apartment scores\n",
        "        data['APARTMENTS_SUM_AVG'] = data['APARTMENTS_AVG'] + data['BASEMENTAREA_AVG'] + data['YEARS_BEGINEXPLUATATION_AVG'] + data[\n",
        "                                    'YEARS_BUILD_AVG'] + data['COMMONAREA_AVG'] + data['ELEVATORS_AVG'] + data['ENTRANCES_AVG'] + data[\n",
        "                                    'FLOORSMAX_AVG'] + data['FLOORSMIN_AVG'] + data['LANDAREA_AVG'] + data['LIVINGAPARTMENTS_AVG'] + data[\n",
        "                                    'LIVINGAREA_AVG'] + data['NONLIVINGAPARTMENTS_AVG'] + data['NONLIVINGAREA_AVG']\n",
        "\n",
        "        data['APARTMENTS_SUM_MODE'] = data['APARTMENTS_MODE'] + data['BASEMENTAREA_MODE'] + data['YEARS_BEGINEXPLUATATION_MODE'] + data[\n",
        "                                    'YEARS_BUILD_MODE'] + data['COMMONAREA_MODE'] + data['ELEVATORS_MODE'] + data['ENTRANCES_MODE'] + data[\n",
        "                                    'FLOORSMAX_MODE'] + data['FLOORSMIN_MODE'] + data['LANDAREA_MODE'] + data['LIVINGAPARTMENTS_MODE'] + data[\n",
        "                                    'LIVINGAREA_MODE'] + data['NONLIVINGAPARTMENTS_MODE'] + data['NONLIVINGAREA_MODE'] + data['TOTALAREA_MODE']\n",
        "\n",
        "        data['APARTMENTS_SUM_MEDI'] = data['APARTMENTS_MEDI'] + data['BASEMENTAREA_MEDI'] + data['YEARS_BEGINEXPLUATATION_MEDI'] + data[\n",
        "                                    'YEARS_BUILD_MEDI'] + data['COMMONAREA_MEDI'] + data['ELEVATORS_MEDI'] + data['ENTRANCES_MEDI'] + data[\n",
        "                                    'FLOORSMAX_MEDI'] + data['FLOORSMIN_MEDI'] + data['LANDAREA_MEDI'] + data['LIVINGAPARTMENTS_MEDI'] + data[\n",
        "                                    'LIVINGAREA_MEDI'] + data['NONLIVINGAPARTMENTS_MEDI'] + data['NONLIVINGAREA_MEDI']\n",
        "        data['INCOME_APARTMENT_AVG_MUL'] = data['APARTMENTS_SUM_AVG'] * data['AMT_INCOME_TOTAL']\n",
        "        data['INCOME_APARTMENT_MODE_MUL'] = data['APARTMENTS_SUM_MODE'] * data['AMT_INCOME_TOTAL']\n",
        "        data['INCOME_APARTMENT_MEDI_MUL'] = data['APARTMENTS_SUM_MEDI'] * data['AMT_INCOME_TOTAL']\n",
        "        #OBS And DEF\n",
        "        data['OBS_30_60_SUM'] = data['OBS_30_CNT_SOCIAL_CIRCLE'] + data['OBS_60_CNT_SOCIAL_CIRCLE']\n",
        "        data['DEF_30_60_SUM'] = data['DEF_30_CNT_SOCIAL_CIRCLE'] + data['DEF_60_CNT_SOCIAL_CIRCLE']\n",
        "        data['OBS_DEF_30_MUL'] = data['OBS_30_CNT_SOCIAL_CIRCLE'] *  data['DEF_30_CNT_SOCIAL_CIRCLE']\n",
        "        data['OBS_DEF_60_MUL'] = data['OBS_60_CNT_SOCIAL_CIRCLE'] *  data['DEF_60_CNT_SOCIAL_CIRCLE']\n",
        "        data['SUM_OBS_DEF_ALL'] = data['OBS_30_CNT_SOCIAL_CIRCLE'] + data['DEF_30_CNT_SOCIAL_CIRCLE'] + data[\n",
        "                                    'OBS_60_CNT_SOCIAL_CIRCLE'] + data['DEF_60_CNT_SOCIAL_CIRCLE']\n",
        "        data['OBS_30_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['OBS_30_CNT_SOCIAL_CIRCLE'] + 0.00001)\n",
        "        data['OBS_60_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['OBS_60_CNT_SOCIAL_CIRCLE'] + 0.00001)\n",
        "        data['DEF_30_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['DEF_30_CNT_SOCIAL_CIRCLE'] + 0.00001)\n",
        "        data['DEF_60_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['DEF_60_CNT_SOCIAL_CIRCLE'] + 0.00001)\n",
        "        #Flag Documents combined\n",
        "        data['SUM_FLAGS_DOCUMENTS'] = data['FLAG_DOCUMENT_3'] + data['FLAG_DOCUMENT_5'] + data['FLAG_DOCUMENT_6']  + data[\n",
        "                                    'FLAG_DOCUMENT_7'] + data['FLAG_DOCUMENT_8'] + data['FLAG_DOCUMENT_9'] + data[\n",
        "                                    'FLAG_DOCUMENT_11'] + data['FLAG_DOCUMENT_13'] + data['FLAG_DOCUMENT_14'] + data[\n",
        "                                    'FLAG_DOCUMENT_15'] + data['FLAG_DOCUMENT_16'] + data['FLAG_DOCUMENT_17'] + data[\n",
        "                                    'FLAG_DOCUMENT_18'] + data['FLAG_DOCUMENT_19'] + data['FLAG_DOCUMENT_21']\n",
        "        #details change\n",
        "        data['DAYS_DETAILS_CHANGE_MUL'] = data['DAYS_LAST_PHONE_CHANGE'] * data['DAYS_REGISTRATION'] * data['DAYS_ID_PUBLISH']\n",
        "        data['DAYS_DETAILS_CHANGE_SUM'] = data['DAYS_LAST_PHONE_CHANGE'] + data['DAYS_REGISTRATION'] + data['DAYS_ID_PUBLISH']\n",
        "        #enquires\n",
        "        data['AMT_ENQ_SUM'] = data['AMT_REQ_CREDIT_BUREAU_HOUR'] + data['AMT_REQ_CREDIT_BUREAU_DAY'] + data['AMT_REQ_CREDIT_BUREAU_WEEK'] + data[\n",
        "                            'AMT_REQ_CREDIT_BUREAU_MON'] + data['AMT_REQ_CREDIT_BUREAU_QRT'] + data['AMT_REQ_CREDIT_BUREAU_YEAR']\n",
        "        data['ENQ_CREDIT_RATIO'] = data['AMT_ENQ_SUM'] / (data['AMT_CREDIT'] + 0.00001)\n",
        "        \n",
        "        #we need to predict count_payment for our given data\n",
        "        test_data = data[['AMT_CREDIT','AMT_ANNUITY']].fillna(0)\n",
        "        test_data['CREDIT_ANNUITY_RATIO'] = test_data['AMT_CREDIT'] / (test_data['AMT_ANNUITY'] + 1)\n",
        "        cnt_payment = self.cnt_payment_lgbmr.predict(test_data)\n",
        "        del test_data\n",
        "        data['EXPECTED_CNT_PAYMENT'] = cnt_payment\n",
        "        data['EXPECTED_INTEREST'] = data['AMT_ANNUITY'] *  data['EXPECTED_CNT_PAYMENT'] - data['AMT_CREDIT']\n",
        "        data['EXPECTED_INTEREST_SHARE'] = data['EXPECTED_INTEREST'] / (data['AMT_CREDIT'] + 0.00001)\n",
        "        data['EXPECTED_INTEREST_RATE'] = 2 * 12 * data['EXPECTED_INTEREST'] / (data['AMT_CREDIT'] * (data['EXPECTED_CNT_PAYMENT'] + 1))\n",
        "        \n",
        "        #predicting the mean of TARGET of 500 neighbors of test data\n",
        "        test_data_for_neighbors = data[['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','CREDIT_ANNUITY_RATIO']].fillna(0)\n",
        "        test_500_neighbors = self.knn_target_500_neighbors.kneighbors(test_data_for_neighbors)[1]\n",
        "        data['TARGET_NEIGHBORS_500_MEAN'] = [self.TARGET.iloc[ele].mean() for ele in test_500_neighbors]\n",
        "\n",
        "        #creating features based on categorical interactions\n",
        "        columns_to_aggregate_on = [\n",
        "            ['NAME_CONTRACT_TYPE', 'NAME_INCOME_TYPE', 'OCCUPATION_TYPE'],\n",
        "            ['CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE'],\n",
        "            ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE'],\n",
        "            ['NAME_EDUCATION_TYPE','NAME_INCOME_TYPE','OCCUPATION_TYPE'],\n",
        "            ['OCCUPATION_TYPE','ORGANIZATION_TYPE'],\n",
        "            ['CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY']\n",
        "        ]\n",
        "        for index, group in enumerate(columns_to_aggregate_on):\n",
        "            group_stats = self.group_interactions_tables[index]\n",
        "            data = data.join(group_stats, on = group)\n",
        "        \n",
        "        #response coding for categorical columns\n",
        "        categorical_columns = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
        "        for col in categorical_columns:\n",
        "            #loading the dictionary with values corresponding to TARGET variable 0 and 1 for each of the categories\n",
        "            with open(self.file_directory + 'Response Coding/' + f'Response_coding_dict_{col}.pkl', 'rb') as f:\n",
        "                mapping_dictionary_column = pickle.load(f)\n",
        "            #mapping this dictionary with our DataFrame\n",
        "            data[col + '_0'] = data[col].map(mapping_dictionary_column[0])\n",
        "            data[col + '_1'] = data[col].map(mapping_dictionary_column[1])\n",
        "            #removing the original categorical columns\n",
        "            _ = data.pop(col)\n",
        "            \n",
        "        #merging with the relational table\n",
        "        data = data.merge(self.relational_table, on = 'SK_ID_CURR', how = 'left')\n",
        "\n",
        "        #adding features based on interactions between different tables\n",
        "        \n",
        "        #previous_application columns\n",
        "        prev_annuity_columns =  ['AMT_ANNUITY_MEAN_LAST_5', 'AMT_ANNUITY_SUM_LAST_5', 'AMT_ANNUITY_MAX_LAST_5', 'AMT_ANNUITY_MEAN_FIRST_2',\n",
        "                                 'AMT_ANNUITY_SUM_FIRST_2', 'AMT_ANNUITY_MAX_FIRST_2', 'AMT_ANNUITY_MEAN_ALL', 'AMT_ANNUITY_SUM_ALL', 'AMT_ANNUITY_MAX_ALL']\n",
        "        for col in prev_annuity_columns:\n",
        "            data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        prev_goods_columns = ['AMT_GOODS_PRICE_MEAN_LAST_5', 'AMT_GOODS_PRICE_MAX_LAST_5', 'AMT_GOODS_PRICE_SUM_LAST_5', 'AMT_GOODS_PRICE_MEAN_FIRST_2',\n",
        "                              'AMT_GOODS_PRICE_MAX_FIRST_2', 'AMT_GOODS_PRICE_SUM_FIRST_2', 'AMT_GOODS_PRICE_MEAN_ALL', 'AMT_GOODS_PRICE_MAX_ALL',\n",
        "                              'AMT_GOODS_PRICE_SUM_ALL']\n",
        "        for col in prev_goods_columns:\n",
        "            data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)       \n",
        "        #credit_card_balance columns\n",
        "        cc_amt_principal_cols = ['AMT_RECEIVABLE_PRINCIPAL_SUM', 'AMT_RECEIVABLE_PRINCIPAL_MEAN', 'AMT_RECEIVABLE_PRINCIPAL_MAX', 'EXP_AMT_RECEIVABLE_PRINCIPAL_LAST']\n",
        "        for col in cc_amt_principal_cols:\n",
        "            data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        cc_amt_recivable_cols = ['AMT_RECIVABLE_SUM', 'AMT_RECIVABLE_MEAN', 'AMT_RECIVABLE_MAX', 'EXP_AMT_RECIVABLE_LAST']\n",
        "        for col in cc_amt_recivable_cols:\n",
        "            data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        cc_amt_total_receivable_cols = ['AMT_TOTAL_RECEIVABLE_SUM', 'AMT_TOTAL_RECEIVABLE_MEAN', 'AMT_TOTAL_RECEIVABLE_MAX', 'EXP_AMT_TOTAL_RECEIVABLE_LAST']\n",
        "        for col in cc_amt_total_receivable_cols:\n",
        "            data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        #installments_payments columns\n",
        "        installments_payment_cols = ['AMT_PAYMENT_MEAN_MEAN', 'AMT_PAYMENT_MEAN_SUM', 'AMT_PAYMENT_MEAN_MAX', 'AMT_PAYMENT_SUM_MEAN', 'AMT_PAYMENT_SUM_SUM',\n",
        "                                     'AMT_PAYMENT_SUM_MAX', 'AMT_PAYMENT_MAX_MEAN', 'AMT_PAYMENT_MEAN_LAST_1_YEAR', 'AMT_PAYMENT_SUM_LAST_1_YEAR',\n",
        "                                     'AMT_PAYMENT_MAX_LAST_1_YEAR', 'AMT_PAYMENT_MEAN_FIRST_5_INSTALLMENTS', 'AMT_PAYMENT_SUM_FIRST_5_INSTALLMENTS',\n",
        "                                     'AMT_PAYMENT_MAX_FIRST_5_INSTALLMENTS']\n",
        "        for col in installments_payment_cols:\n",
        "            data['INSTALLMENTS_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        installments_max_installment = ['AMT_INSTALMENT_MEAN_MAX', 'AMT_INSTALMENT_SUM_MAX']\n",
        "        for col in installments_max_installment:\n",
        "            data['INSTALLMENTS_ANNUITY_' + col + '_RATIO'] = data['AMT_ANNUITY'] / (data[col] + 0.00001)\n",
        "        #bureau and bureau_balance columns\n",
        "        bureau_days_credit_cols = ['DAYS_CREDIT_MEAN_OVERALL', 'DAYS_CREDIT_MEAN_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_MIN_CREDITACTIVE_CLOSED',\n",
        "                                   'DAYS_CREDIT_MAX_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_LAST_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_MEAN_CREDITACTIVE_ACTIVE',\n",
        "                                   'DAYS_CREDIT_MIN_CREDITACTIVE_ACTIVE', 'DAYS_CREDIT_MAX_CREDITACTIVE_ACTIVE', 'DAYS_CREDIT_LAST_CREDITACTIVE_ACTIVE',\n",
        "                                   'DAYS_CREDIT_MEANCREDIT_ACTIVE_REST', 'DAYS_CREDIT_MINCREDIT_ACTIVE_REST', 'DAYS_CREDIT_MAXCREDIT_ACTIVE_REST',\n",
        "                                   'DAYS_CREDIT_LASTCREDIT_ACTIVE_REST']\n",
        "        for col in bureau_days_credit_cols:\n",
        "            data['BUREAU_' + col + '_EMPLOYED_DIFF'] = data[col] - data['DAYS_EMPLOYED']\n",
        "            data['BUREAU_' + col + '_REGISTRATION_DIFF'] = data[col] - data['DAYS_REGISTRATION']  \n",
        "        bureau_overdue_cols = ['AMT_CREDIT_MAX_OVERDUE_MEAN_OVERALL', 'AMT_CREDIT_SUM_OVERDUE_MEAN_OVERALL', 'AMT_CREDIT_MAX_OVERDUE_MAX_CREDITACTIVE_CLOSED',\n",
        "                               'AMT_CREDIT_MAX_OVERDUE_SUM_CREDITACTIVE_CLOSED', 'AMT_CREDIT_SUM_OVERDUE_MAX_CREDITACTIVE_CLOSED', 'AMT_CREDIT_SUM_OVERDUE_SUM_CREDITACTIVE_CLOSED',\n",
        "                               'AMT_CREDIT_MAX_OVERDUE_MAX_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_MAX_OVERDUE_SUM_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_SUM_OVERDUE_MAX_CREDITACTIVE_ACTIVE',\n",
        "                                'AMT_CREDIT_SUM_OVERDUE_SUM_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_MAX_OVERDUE_MAXCREDIT_ACTIVE_REST', 'AMT_CREDIT_MAX_OVERDUE_SUMCREDIT_ACTIVE_REST',\n",
        "                               'AMT_CREDIT_SUM_OVERDUE_MAXCREDIT_ACTIVE_REST', 'AMT_CREDIT_SUM_OVERDUE_SUMCREDIT_ACTIVE_REST']\n",
        "        for col in bureau_overdue_cols:\n",
        "            data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
        "        bureau_amt_annuity_cols = ['AMT_ANNUITY_MEAN_OVERALL']\n",
        "        for col in bureau_amt_annuity_cols:\n",
        "            data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)  \n",
        "            \n",
        "        #removing some non-useful features\n",
        "        data = data[self.final_cols]\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def final_function_1(self, input_data):\n",
        "        '''\n",
        "        Function 1 for prediction. This function takes one argument that is the test datapoint, and prints the prediction for that point.\n",
        "        \n",
        "        Inputs:\n",
        "            self\n",
        "            input_data: DataFrame\n",
        "                The test datapoint, whose Target is to be predicted\n",
        "        \n",
        "        Returns:\n",
        "            None\n",
        "        '''\n",
        "        \n",
        "        start_time = datetime.now()\n",
        "        #first preprocessing it\n",
        "        test_data = self.preprocessing(input_data)\n",
        "        #making the predictions\n",
        "        test_predicted_probability = np.zeros(len(input_data))\n",
        "        for model in [self.final_xgb_1, self.final_xgb_2, self.final_xgb_3]:\n",
        "            test_predicted_probability += model.predict_proba(test_data, ntree_limit = model.get_booster().best_ntree_limit)[:,1] / 3\n",
        "        predicted_class_label = np.where(test_predicted_probability > self.threshold, 1, 0)\n",
        "        \n",
        "        #printing the results\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Predicted Probabilties for given Client(s) being Defaulter is/are: {np.round(test_predicted_probability, 4)}\")\n",
        "        print(f\"The class label for given query point is: {predicted_class_label}\")\n",
        "        print(f\"Total Time Taken for prediction = {datetime.now() - start_time}\")\n",
        "        print('-' * 100)\n",
        "        \n",
        "    def final_function_2(self, input_data, target):\n",
        "        '''\n",
        "        Function 2 for prediction. This function takes both the Test Point and Target value of that point. It returns\n",
        "        the prediction along with the metric for the predicted points.\n",
        "        \n",
        "        Inputs:\n",
        "            self\n",
        "            input_data: DataFrame\n",
        "                Test Datapoint\n",
        "            target: Series\n",
        "                Target value corresponding to test points\n",
        "        \n",
        "        Returns:\n",
        "            None\n",
        "        '''\n",
        "        \n",
        "        start_time = datetime.now()\n",
        "        #first preprocessing the input data\n",
        "        test_data = self.preprocessing(input_data)\n",
        "        \n",
        "        #making predictions\n",
        "        test_predicted_probability = np.zeros(input_data.shape[0])\n",
        "        for model in [self.final_xgb_1, self.final_xgb_2, self.final_xgb_3]:\n",
        "            test_predicted_probability += model.predict_proba(test_data, ntree_limit = model.get_booster().best_ntree_limit)[:,1] / 3\n",
        "\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Predicted Probabilties for given Client(s) being Defaulter is/are:\\n{np.round(test_predicted_probability, 4)}\")\n",
        "        predicted_classes = np.where(test_predicted_probability > self.threshold, 1, 0)\n",
        "        print(f\"\\nThe predicted class labels are:\\n{predicted_classes}\")\n",
        "        #if there are more than 1 input, printing the Metrics\n",
        "        if len(input_data)>1:\n",
        "            print('-' * 100)\n",
        "            print(\"\\nThe Performance Metrics are:\\n\")\n",
        "            try:\n",
        "                print(f\"ROC-AUC Score = {roc_auc_score(target, test_predicted_probability)}\")\n",
        "            except:\n",
        "                print(\"Cannot calculate ROC-AUC Score as the Test Datapoints have only 1 type of Class Labels present. Try with different Datapoints\")\n",
        "            print(f\"Recall Score = {recall_score(target, predicted_classes)}\")\n",
        "        print(f\"Total Time taken for prediction = {datetime.now() - start_time}\")\n",
        "        print(\"-\" * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:02.306395Z",
          "start_time": "2020-10-30T01:29:58.617573Z"
        },
        "id": "Pst6nNE9pwiZ"
      },
      "source": [
        "train_data = pd.read_csv('application_train.csv')\n",
        "test_data = pd.read_csv('application_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:05.816630Z",
          "start_time": "2020-10-30T01:30:02.308261Z"
        },
        "id": "IDR9lN4fpwib"
      },
      "source": [
        "testing_class = final_pipeline(file_directory = 'Final Pipeline Files/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:05.859476Z",
          "start_time": "2020-10-30T01:30:05.818597Z"
        },
        "id": "qG9LTKoLpwid",
        "outputId": "c28ffbd1-ca42-4826-e83d-578c46598df4"
      },
      "source": [
        "test_datapoint_func_1 = test_data.sample(1)\n",
        "print(\"Out test query point for Testing Function 1 of pipeline is:\")\n",
        "display(test_datapoint_func_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out test query point for Testing Function 1 of pipeline is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>NAME_CONTRACT_TYPE</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>AMT_GOODS_PRICE</th>\n",
              "      <th>...</th>\n",
              "      <th>FLAG_DOCUMENT_18</th>\n",
              "      <th>FLAG_DOCUMENT_19</th>\n",
              "      <th>FLAG_DOCUMENT_20</th>\n",
              "      <th>FLAG_DOCUMENT_21</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42679</th>\n",
              "      <td>411334</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>360000.0</td>\n",
              "      <td>27990.0</td>\n",
              "      <td>360000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
              "42679      411334         Cash loans           M            Y               N   \n",
              "\n",
              "       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
              "42679             1          157500.0    360000.0      27990.0   \n",
              "\n",
              "       AMT_GOODS_PRICE  ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
              "42679         360000.0  ...                0                0   \n",
              "\n",
              "      FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
              "42679                0                0                        0.0   \n",
              "\n",
              "       AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
              "42679                        0.0                         0.0   \n",
              "\n",
              "       AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
              "42679                        0.0                        1.0   \n",
              "\n",
              "       AMT_REQ_CREDIT_BUREAU_YEAR  \n",
              "42679                         1.0  \n",
              "\n",
              "[1 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:23.980009Z",
          "start_time": "2020-10-30T01:30:19.356086Z"
        },
        "id": "udtMwIOupwie",
        "outputId": "7ca7cd7b-447b-4176-a89a-3169a0cc6bba"
      },
      "source": [
        "#predicting the output\n",
        "testing_class.final_function_1(test_datapoint_func_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted Probabilties for given Client(s) being Defaulter is/are: [0.0325]\n",
            "The class label for given query point is: [0]\n",
            "Total Time Taken for prediction = 0:00:04.619899\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:48.343379Z",
          "start_time": "2020-10-30T01:30:48.303487Z"
        },
        "id": "3BgXjAt7pwif",
        "outputId": "2ac6c2ac-7e9b-4b56-b774-f95e5aa1d54c"
      },
      "source": [
        "test_datapoint_func_2 = train_data.sample(50).copy()\n",
        "targets_func_2 = test_datapoint_func_2.pop('TARGET')\n",
        "print(\"Some of the Test Query points for Testing Function 2 of pipeline is:\")\n",
        "display(test_datapoint_func_2.head(5))\n",
        "print(\"Target Labels of These Datapoints are:\")\n",
        "print(targets_func_2.values[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some of the Test Query points for Testing Function 2 of pipeline is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>NAME_CONTRACT_TYPE</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>AMT_GOODS_PRICE</th>\n",
              "      <th>...</th>\n",
              "      <th>FLAG_DOCUMENT_18</th>\n",
              "      <th>FLAG_DOCUMENT_19</th>\n",
              "      <th>FLAG_DOCUMENT_20</th>\n",
              "      <th>FLAG_DOCUMENT_21</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78113</th>\n",
              "      <td>190563</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>276277.5</td>\n",
              "      <td>21955.5</td>\n",
              "      <td>238500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34900</th>\n",
              "      <td>140442</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>405000.0</td>\n",
              "      <td>473841.0</td>\n",
              "      <td>27333.0</td>\n",
              "      <td>387000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101397</th>\n",
              "      <td>217721</td>\n",
              "      <td>Revolving loans</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>540000.0</td>\n",
              "      <td>27000.0</td>\n",
              "      <td>540000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273670</th>\n",
              "      <td>417196</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>545040.0</td>\n",
              "      <td>19705.5</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264529</th>\n",
              "      <td>406351</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>485640.0</td>\n",
              "      <td>39069.0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
              "78113       190563         Cash loans           F            N   \n",
              "34900       140442         Cash loans           M            N   \n",
              "101397      217721    Revolving loans           F            Y   \n",
              "273670      417196         Cash loans           F            N   \n",
              "264529      406351         Cash loans           F            N   \n",
              "\n",
              "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
              "78113                N             0           90000.0    276277.5   \n",
              "34900                N             0          405000.0    473841.0   \n",
              "101397               Y             0          315000.0    540000.0   \n",
              "273670               Y             0           90000.0    545040.0   \n",
              "264529               N             1          135000.0    485640.0   \n",
              "\n",
              "        AMT_ANNUITY  AMT_GOODS_PRICE  ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
              "78113       21955.5         238500.0  ...                0                0   \n",
              "34900       27333.0         387000.0  ...                0                0   \n",
              "101397      27000.0         540000.0  ...                0                0   \n",
              "273670      19705.5         450000.0  ...                0                0   \n",
              "264529      39069.0         450000.0  ...                0                0   \n",
              "\n",
              "       FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
              "78113                 0                0                        NaN   \n",
              "34900                 0                0                        0.0   \n",
              "101397                0                0                        0.0   \n",
              "273670                0                0                        0.0   \n",
              "264529                0                0                        0.0   \n",
              "\n",
              "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
              "78113                         NaN                         NaN   \n",
              "34900                         0.0                         0.0   \n",
              "101397                        0.0                         0.0   \n",
              "273670                        0.0                         0.0   \n",
              "264529                        0.0                         0.0   \n",
              "\n",
              "        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
              "78113                         NaN                        NaN   \n",
              "34900                         0.0                        1.0   \n",
              "101397                        0.0                        0.0   \n",
              "273670                        0.0                        0.0   \n",
              "264529                        0.0                        2.0   \n",
              "\n",
              "        AMT_REQ_CREDIT_BUREAU_YEAR  \n",
              "78113                          NaN  \n",
              "34900                          2.0  \n",
              "101397                         5.0  \n",
              "273670                         2.0  \n",
              "264529                         4.0  \n",
              "\n",
              "[5 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Target Labels of These Datapoints are:\n",
            "[1 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-30T01:30:53.917207Z",
          "start_time": "2020-10-30T01:30:51.079834Z"
        },
        "scrolled": false,
        "id": "YCRB2PUtpwig",
        "outputId": "bd160c21-cc8c-41f6-83fe-1f213b301cc9"
      },
      "source": [
        "#predicting the outputs and calculating the metrics of given datapoints\n",
        "testing_class.final_function_2(test_datapoint_func_2, targets_func_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted Probabilties for given Client(s) being Defaulter is/are:\n",
            "[0.1629 0.0674 0.1167 0.0264 0.2014 0.0299 0.0456 0.0228 0.068  0.1167\n",
            " 0.2729 0.0413 0.0499 0.0753 0.1104 0.0553 0.0438 0.0454 0.0269 0.0316\n",
            " 0.0547 0.0277 0.019  0.1014 0.0146 0.0226 0.0368 0.1743 0.0705 0.0337\n",
            " 0.0275 0.0904 0.0238 0.0516 0.0167 0.0353 0.0747 0.1236 0.0203 0.0865\n",
            " 0.0841 0.3123 0.0786 0.0775 0.0276 0.2983 0.0373 0.0764 0.0527 0.0395]\n",
            "\n",
            "The predicted class labels are:\n",
            "[1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "The Performance Metrics are:\n",
            "\n",
            "ROC-AUC Score = 0.8901515151515151\n",
            "Recall Score = 1.0\n",
            "Total Time taken for prediction = 0:00:02.833385\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}